{"cells":[{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import re as reg"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def tokenize_sentence(sentence):\n","    return reg.split('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s',sentence)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def tokenize_word(word):\n","    return word.split(' ')"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def count_words(sentence):\n","    words = {}\n","    for _ in sentence:\n","        try:\n","            words[_]+=1\n","        except:\n","            words[_] = 1\n","    return words"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["with open('input.txt', 'r') as file:\n","    text = file.read()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["sentences = tokenize_sentence(text)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["words = tokenize_word(text)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["SPECEFIC WORDS : \n","['Write', 'a', 'python', 'program', 'to', 'load', 'a', 'sample', 'text', 'corpus', 'file', 'and', 'perform', 'the', 'following', 'operation:\\n1)', 'Tokenize', 'the', 'corpus', 'into', 'words', 'and', 'print', 'the', 'words', 'and', 'word', 'count.\\n2)', 'Calculate', 'the', 'size', 'of', 'vocabulary.\\n3)', 'Tokenize', 'the', 'corpus', 'into', 'sentences', 'and', 'print', 'the', 'sentences', 'and', 'sentence', 'count.', 'Short', 'forms', 'that', 'include', '\".\"', 'should', 'be', 'taken', 'care.\\n4)', 'Prepare', 'a', 'new', 'document', 'by', 'removing', 'the', 'duplicate', 'sentences', 'or', 'multiple', 'instances', 'of', 'a', 'sentence.', 'Assign', 'each', 'sentence', 'a', 'unique', 'id.', 'Display', 'the', 'document.']\n","TOTAL WORD COUNT : \n","{'Write': 1, 'a': 5, 'python': 1, 'program': 1, 'to': 1, 'load': 1, 'sample': 1, 'text': 1, 'corpus': 3, 'file': 1, 'and': 5, 'perform': 1, 'the': 8, 'following': 1, 'operation:\\n1)': 1, 'Tokenize': 2, 'into': 2, 'words': 2, 'print': 2, 'word': 1, 'count.\\n2)': 1, 'Calculate': 1, 'size': 1, 'of': 2, 'vocabulary.\\n3)': 1, 'sentences': 3, 'sentence': 2, 'count.': 1, 'Short': 1, 'forms': 1, 'that': 1, 'include': 1, '\".\"': 1, 'should': 1, 'be': 1, 'taken': 1, 'care.\\n4)': 1, 'Prepare': 1, 'new': 1, 'document': 1, 'by': 1, 'removing': 1, 'duplicate': 1, 'or': 1, 'multiple': 1, 'instances': 1, 'sentence.': 1, 'Assign': 1, 'each': 1, 'unique': 1, 'id.': 1, 'Display': 1, 'document.': 1}\n","VOCABULARY SIZE = 53\n","TOTAL SENTENCE COUNT = 7\n"]}],"source":["print('SPECEFIC WORDS : ')\n","print(words)\n","print('TOTAL WORD COUNT : ')\n","print(count_words(words))\n","print(\"VOCABULARY SIZE = \" + str(len(set(words))))\n","print(\"TOTAL SENTENCE COUNT = \" + str(len(sentences)))\n","sentences = set(sentences)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["with open('output.csv', 'w') as file:\n","    i = 0\n","    for _ in sentences:\n","        file.write(str(i) + ',' + _ + '\\n')\n","        i+=1"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":2}
