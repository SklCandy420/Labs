{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsXGtFeoGy32",
        "outputId": "ae024084-2f2d-4158-cf08-dd5f2cb42fe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('reuters')\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from collections import *\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_flON8FG8_A",
        "outputId": "26a6267b-20cc-4a2a-a767-28b9d60b93e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['### abstract ###',\n",
              " 'The problem of joint universal source coding and modeling, addressed by Rissanen in the context of lossless codes, is generalized to fixed-rate lossy coding of continuous-alphabet memoryless sources']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "corpus = '''### abstract ###\n",
        "The problem of joint universal source coding and modeling, addressed by Rissanen in the context of lossless codes, is generalized to fixed-rate lossy coding of continuous-alphabet memoryless sources\n",
        "We show that, for bounded distortion measures, any compactly parametrized family of  iid \n",
        "real vector sources with absolutely continuous marginals (satisfying appropriate smoothness and Vapnik--Chervonenkis learnatwolity conditions) admits a joint scheme for universal lossy block coding and parameter estimation, and give nonasymptotic estimates of convergence rates for distortion redundancies and variational distances between the active source and the estimated source\n",
        "We also present explicit examples of parametric sources admitting such joint universal compression and modeling schemes\n",
        "### introduction ###\n",
        "In universal data compression, a single code achieves asymptotically optimal performance on all sources within a given family\n",
        "Intuition suggests that a good universal coder should acquire an accurate model of the source statistics from a sufficiently long data sequence and incorporate this knowledge in its operation\n",
        "For lossless codes, this intuition has been made rigorous by Rissanen  CITATION\n",
        "Under his scheme, the data are encoded in a  two-stage  set-up, in which the twonary representation of each source block consists of two parts: (1) a suitably quantized maximum-likelihood estimate of the source parameters, and (2) lossless encoding of the data matched to the acquired model; the redundancy of the resulting code converges to zero as  SYMBOL , where  SYMBOL  is the block length\n",
        "In this paper, we extend Rissanen's idea to  lossy  block coding (vector quantization) of  iid \n",
        "sources with values in  SYMBOL  for some finite  SYMBOL\n",
        "Specifically, let  SYMBOL  be an  iid \n",
        "source with the marginal distribution of  SYMBOL  belonging to some indexed class  SYMBOL  of absolutely continuous distributions on  SYMBOL , where  SYMBOL  is a bounded subset of  SYMBOL  for some  SYMBOL\n",
        "For bounded distortion measures, our main result, Theorem~, states that if the class  SYMBOL  satisfies certain smoothness and learnatwolity conditions, then there exists a sequence of finite-memory lossy block codes that achieves asymptotically optimal compression of each source in the class and permits asymptotically exact identification of the active source with respect to the  variational distance , defined as  SYMBOL , where the supremum is over all Borel subsets of  SYMBOL\n",
        "The overhead rate and the distortion redundancy of the scheme converge to zero as  SYMBOL  and  SYMBOL , respectively, where  SYMBOL  is the block length, while the active source can be identified up to a variational ball of radius  SYMBOL  eventually almost surely\n",
        "We also describe an extension of our scheme to unbounded distortion measures satisfying a certain moment condition, and present two examples of parametric families satisfying the regularity conditions of Theorem~\n",
        "While most existing schemes for universal lossy coding rely on  implicit  identification of the active source (e g , through topological covering arguments  CITATION , Glivenko--Cantelli uniform laws of large numbers  CITATION , or nearest-neighbor code clustering  CITATION ), our code builds an  explicit model  of the mechanism responsible for generating the data and then selects an appropriate code for the data on the basis of the model\n",
        "This atwolity to simultaneously model and compress the data may prove useful in such applications as  media forensics   CITATION , where the parameter  SYMBOL  could represent evidence of tampering, and the aim is to compress the data in such a way that the evidence can be later extracted with high fidelity from the compressed version\n",
        "Another key feature of our approach is the use of Vapnik--Chervonenkis theory  CITATION  in order to connect universal encodatwolity of a class of sources to the comtwonatorial ``richness\" of a certain collection of decision regions associated with the sources\n",
        "In a way, Vapnik--Chervonenkis estimates can be thought of as an (imperfect) analogue of the comtwonatorial method of types for finite alphabets  CITATION\n",
        "'''\n",
        "\n",
        "# imput the reuters sentences\n",
        "Sentences = corpus.split('\\n')\n",
        "Sentences[:2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOY2eBVVG87x",
        "outputId": "9d06b1eb-e9b2-4e02-ac31-d3050cae4e15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['mightn',\n",
              " 'yours',\n",
              " 'am',\n",
              " 'hasn',\n",
              " 'whom',\n",
              " 't',\n",
              " \"hadn't\",\n",
              " 'too',\n",
              " 'because',\n",
              " 'didn']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# write the removal characters such as : Stopwords and punctuation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "string.punctuation = string.punctuation +'\"'+'\"'+'-'+'''+'''+'â€”'\n",
        "string.punctuation\n",
        "rem_array = list(stop_words) + list(string.punctuation)+ ['lt','rt']\n",
        "rem_array[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fIlC4rWG8ww",
        "outputId": "781ae95e-ec22-472b-9661-94e97128fb0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['###', 'abstract', '###']\n",
            "[['###', 'abstract', '###'], ['the', 'problem', 'of', 'joint', 'universal', 'source', 'coding', 'and', 'modeling,', 'addressed', 'by', 'rissanen', 'in', 'the', 'context', 'of', 'lossless', 'codes,', 'is', 'generalized', 'to', 'fixed-rate', 'lossy', 'coding', 'of', 'continuous-alphabet', 'memoryless', 'sources']]\n",
            "['###', 'abstract', '###', 'the', 'problem', 'of', 'joint', 'universal', 'source', 'coding']\n",
            "[(None, '###'), ('###', 'abstract'), ('abstract', '###'), ('###', None), (None, 'the'), ('the', 'problem'), ('problem', 'of'), ('of', 'joint'), ('joint', 'universal'), ('universal', 'source')]\n"
          ]
        }
      ],
      "source": [
        "# generate onegrams twograms threegrams\n",
        "onegram = []\n",
        "twogram=[]\n",
        "threegram=[]\n",
        "fourgram=[]\n",
        "tokenized_text=[]\n",
        "for i,sentence in enumerate(Sentences):\n",
        "    sentence = list(map(lambda x:x.lower(),sentence.split()))\n",
        "    if i==0:\n",
        "      print(sentence)\n",
        "    for word in sentence:\n",
        "        if word == '.':\n",
        "            sentence.remove(word)\n",
        "        else:\n",
        "            onegram.append(word)\n",
        "    \n",
        "    tokenized_text.append(sentence)\n",
        "    twogram.extend(list(ngrams(sentence, 2,pad_left=True, pad_right=True)))\n",
        "    fourgram.extend(list(ngrams(sentence, 4, pad_left=True, pad_right=True)))\n",
        "\n",
        "print(tokenized_text[:2])\n",
        "print(onegram[:10])\n",
        "print(twogram[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyud453bG8uu",
        "outputId": "efe8435f-81b6-42d1-a63a-66f881f0a9fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the\n",
            "of\n",
            "and\n",
            "by\n",
            "in\n",
            "the\n",
            "of\n",
            "is\n",
            "to\n",
            "of\n",
            "--------------------------------------------\n",
            "('in', 'the')\n",
            "('between', 'the')\n",
            "('and', 'the')\n",
            "('on', 'all')\n",
            "('that', 'a')\n",
            "('of', 'the')\n",
            "('from', 'a')\n",
            "('in', 'its')\n",
            "('has', 'been')\n",
            "('under', 'his')\n",
            "--------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# remove the n-grams with removable words\n",
        "def rem_stopwords(x):    \n",
        "    y = []\n",
        "    count = 0\n",
        "    for pair in x:\n",
        "        flag = 0\n",
        "        if type(pair) == str:\n",
        "          if pair not in rem_array:\n",
        "            y.append(pair)\n",
        "          else:\n",
        "            if count < 10:\n",
        "              print(pair)\n",
        "              count += 1  \n",
        "        else:    \n",
        "          for word in pair:\n",
        "              if word in rem_array:\n",
        "                  flag = flag or 0\n",
        "              else:\n",
        "                  flag = flag or 1\n",
        "          if (flag==1):\n",
        "              y.append(pair)\n",
        "          else:\n",
        "            if count < 10: \n",
        "              print(pair)\n",
        "              count += 1    \n",
        "    return (y)\n",
        "onegram = rem_stopwords(onegram)\n",
        "print('--------------------------------------------')\n",
        "twogram = rem_stopwords(twogram)\n",
        "print('--------------------------------------------')\n",
        "fourgram = rem_stopwords(fourgram)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaiJDSltN825"
      },
      "outputs": [],
      "source": [
        "freq_two = FreqDist(twogram)\n",
        "freq_two"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot6hDl7WG8sS",
        "outputId": "688ab147-3079-4519-ead8-e3b073ed76c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "source\n",
            "source with\n",
            "source with absolutely\n",
            "source with absolutely continuous\n",
            "source with absolutely continuous marginals\n",
            "source with absolutely continuous marginals (satisfying\n",
            "source with absolutely continuous marginals (satisfying appropriate\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and modeling,\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and modeling, addressed\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and modeling, addressed by\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and modeling, addressed by rissanen\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and modeling, addressed by rissanen in\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and modeling, addressed by rissanen in universal\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and modeling, addressed by rissanen in universal lossy\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and modeling, addressed by rissanen in universal lossy block\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and modeling, addressed by rissanen in universal lossy block coding\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and modeling, addressed by rissanen in universal lossy block coding and\n",
            "source with absolutely continuous marginals (satisfying appropriate smoothness and modeling, addressed by rissanen in universal lossy block coding and modeling,\n"
          ]
        }
      ],
      "source": [
        "def get_next_word(dictionary, current):\n",
        "    if(current == None or (current in dictionary) == False):\n",
        "        return \".\"\n",
        "    max_probatwolity_index = None\n",
        "    for val in dictionary[current]:\n",
        "        if(max_probatwolity_index == None):\n",
        "            max_probatwolity_index = val\n",
        "        else:\n",
        "            if dictionary[current][val] > dictionary[current][max_probatwolity_index]:\n",
        "                max_probatwolity_index = val\n",
        "    return max_probatwolity_index\n",
        "two_freq_dist = FreqDist(twogram)\n",
        "dictionary={}\n",
        "for a, b in two_freq_dist:\n",
        "    if(a != None and b!= None):\n",
        "        if((a in dictionary) == False):\n",
        "            dictionary[a] = {}\n",
        "        dictionary[a][b] = two_freq_dist[a, b]\n",
        "\n",
        "prefix = \"source\"\n",
        "print(prefix)\n",
        "s = prefix\n",
        "for i in range(19):\n",
        "    suffix = get_next_word(dictionary,prefix)\n",
        "    s=s+' '+suffix\n",
        "    print(s)\n",
        "    prefix = suffix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8PNuegrG8oe",
        "outputId": "bbc44219-6e08-4bf4-becf-97646fe690e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "with the marginal\n",
            "with the marginal distribution\n",
            "with the marginal distribution of\n",
            "with the marginal distribution of symbol\n",
            "with the marginal distribution of symbol belonging\n",
            "with the marginal distribution of symbol belonging to\n",
            "with the marginal distribution of symbol belonging to some\n",
            "with the marginal distribution of symbol belonging to some indexed\n",
            "with the marginal distribution of symbol belonging to some indexed class\n",
            "with the marginal distribution of symbol belonging to some indexed class symbol\n",
            "with the marginal distribution of symbol belonging to some indexed class symbol of\n",
            "with the marginal distribution of symbol belonging to some indexed class symbol of absolutely\n",
            "with the marginal distribution of symbol belonging to some indexed class symbol of absolutely continuous\n",
            "with the marginal distribution of symbol belonging to some indexed class symbol of absolutely continuous distributions\n",
            "with the marginal distribution of symbol belonging to some indexed class symbol of absolutely continuous distributions on\n",
            "with the marginal distribution of symbol belonging to some indexed class symbol of absolutely continuous distributions on symbol\n",
            "with the marginal distribution of symbol belonging to some indexed class symbol of absolutely continuous distributions on symbol ,\n",
            "with the marginal distribution of symbol belonging to some indexed class symbol of absolutely continuous distributions on symbol , where\n",
            "with the marginal distribution of symbol belonging to some indexed class symbol of absolutely continuous distributions on symbol , where symbol\n",
            "with the marginal distribution of symbol belonging to some indexed class symbol of absolutely continuous distributions on symbol , where symbol is\n"
          ]
        }
      ],
      "source": [
        "four_dict = {}\n",
        "four_freq_dist = FreqDist(fourgram)\n",
        "for a, b, c, e in four_freq_dist:\n",
        "    if(a != None and b!= None and c!= None and e!= None):\n",
        "        if(((a,b,c) in four_dict) == False):\n",
        "            four_dict[a,b,c] = {}\n",
        "        four_dict[a,b,c][e] = four_freq_dist[a,b,c,e]\n",
        " \n",
        "\n",
        "\n",
        "# Next word prediction  \n",
        "s=''\n",
        "prefix = 'with', 'the', 'marginal'\n",
        "print(\" \".join(prefix))\n",
        "s = \" \".join(prefix)\n",
        "for i in range(19):\n",
        "    suffix = get_next_word(four_dict,prefix)\n",
        "    s=s+' '+suffix\n",
        "    print(s)\n",
        "    prefix = prefix[1], prefix[2], suffix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFeoSVaKTbUd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Shannon_Algorithm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
